{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translate all text to English with the help of the Translator package by google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                                             # For the path of the datasets\n",
    "import pandas as pd\n",
    "from googletrans import Translator, constants         # connects to google translate, sometimes doesn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('D:/TU_Graz/Winter Semester 2020-2021/KDDM 2/Project/Datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read the train and test datasets\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator()        # Initialize the translator, if set by default it will detect any language and \n",
    "                                 # translate it to english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Do the same for the test dataset. '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Translate every pair of premise and hypothesis and store them in new columns of the dataset, then save the new\n",
    "dataset. We need only run this once, then we can load the csv file with translations.\"\"\"\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    \n",
    "    if row[\"lang_abv\"] == \"en\":\n",
    "        train.loc[index, \"premise_translated\"] = train.loc[index, \"premise\"]\n",
    "        train.loc[index, \"hypothesis_translated\"] = train.loc[index, \"hypothesis\"]\n",
    "    \n",
    "    else:\n",
    "        train.loc[index, \"premise_translated\"] = translator.translate(train.loc[index, \"premise\"]).text\n",
    "        train.loc[index, \"hypothesis_translated\"] = translator.translate(train.loc[index, \"hypothesis\"]).text\n",
    "\n",
    "train.to_csv(\"train_translated.csv\", index = False)\n",
    "\n",
    "\"\"\" Do the same for the test dataset. \"\"\"\n",
    "for index, row in test.iterrows():\n",
    "    \n",
    "    if row[\"lang_abv\"] == \"en\":\n",
    "        test.loc[index, \"premise_translated\"] = test.loc[index, \"premise\"]\n",
    "        test.loc[index, \"hypothesis_translated\"] = test.loc[index, \"hypothesis\"]\n",
    "    \n",
    "    else:\n",
    "        test.loc[index, \"premise_translated\"] = translator.translate(test.loc[index, \"premise\"]).text\n",
    "        test.loc[index, \"hypothesis_translated\"] = translator.translate(test.loc[index, \"hypothesis\"]).text \n",
    "\n",
    "test.to_csv(\"test_translated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
